\chapter{Summary and Conclusions}
%To conclude
We proposed a new framework for online multi-task learning, where  learners share a single annotator. 
We presented an algorithm (SHAMPO) that works in this settings and analyzed it in the mistake-bound 
model. We also showed how learning in such a model can be used to learn in contextual-bandits setting 
with few types of feedback. Empirical results show that our algorithm does better for the same price. 
It focuses the annotator on the harder instances, and is improving performance in various tasks and settings. 
We plan to integrate other algorithms to our framework,  %and confidence weighted learning,
extend it to other settings, investigate ways to generate good priors, and reduce multi-class to binary also via error-correcting output-codes.

% In this paper we extended the methods of partial feedback and selective sampling algorithms to the 
%multi-task case and  introduced MUTSEA, a new multi-task selective sampling algorithm. 
%The algorithm doesn't force a  same space for all of the tasks inputs and the bound on its expected 
%learning mistakes, shows that the bound  becomes tighter for a certain value of the parameter $b$. 
%Our experiments show that this is indeed the case, and the minimal error is obtained for a certain optimal 
%point. Moreover, the experiments shows that this optimal point can be approximately found,  using only the 
%partial feedback. We plan to study and develop this algorithm into the multi-class direction and try to make 
%the algorithm adaptive such that its single parameter could be adapted iteratively to the data.
