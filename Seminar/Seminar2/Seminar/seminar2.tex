\documentclass{beamer}

\usepackage{amssymb,amsmath,amsfonts,graphicx}
\usepackage[english]{babel}
\usepackage{graphics}
\usepackage{beamerthemesplit} 
\usepackage{beamerthemeshadow}
\usepackage[latin1]{inputenc}
\usefonttheme{professionalfonts}
\usepackage{times}
\usepackage{amsmath}
\usecolortheme{whale}
\usepackage{enumerate}
\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{times}
\usepackage{subfigure}
\usepackage{color}
\usepackage{amsbsy}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{epsfig}
\usepackage{tabulary}
\usepackage{wrapfig}
\usepackage[noadjust]{cite}
\input{prel_eli}




\usetheme{Frankfurt}


\title{Learning Drifting Data \\Using Selective Sampling}    % Enter 


\begin{document}
\maketitle
\section{Introduction}


\section{Classification Analysis}
\begin{frame}{Objectives}
Approaching the problem of shifting concept in an on-line learning classification setting we set the following objectives:
\begin{enumerate}
\item Detect the switch
\item If switch is undetected - assure that the additional regret it causes is small
\item No false detections
\end{enumerate}

\end{frame}

\begin{frame}{Problem Setting}
We work under the following assumptions:
\begin{itemize}
\item $y_t\in\{\pm1\}$
\item $\vxi{t}\in R^d$
\item for $t\leq\tau$ holds $\Exp{y_t}=\vut\vxi{t}$
\item for $t>\tau$ holds $\Exp{y_t}=\vvt\vxi{t}$
\item $\|\vxi{t}\|=\|\vu\|=\|\vv\|=1$
\end{itemize}


\end{frame}

\begin{frame}{BBQ Algorithm}
We submit prediction:
\begin{equation}
\hat{y}_t=\sign\left\{\vwti{t}\vxi{t}\right\}
\end{equation}
\newline
$\vwi{t}$ is our estimation to the optimal linear classifier obtained by solving the following problem:
\begin{equation}
\vwi{t}=\min_{\vw\in R^d}{\left\{\sum\limits_{i=1}^{n}\left(y_i-\vwt\vxi{i}\right)^2+\|\vw\|^2\right\}}
\label{RLS_prob}
\end{equation}
with $n=N_t$ being the number of queries issued until round $t-1$
\end{frame}

\begin{frame}{BBQ Algorithm}
The solution to equation \ref{RLS_prob} is:
\begin{equation}
\vwi{t}=\left(I+S_{t-1}S_{t-1}^T+ \vxi{t} \vxti{t}\right)^{-1}S_{t-1}Y_{t-1}
\label{RLS}
\end{equation}
where $S_{t-1}=(\vxi{1},...,\vxi{n})\in R^{d\times n}$ and $Y_{t-1}=(y_1,...,y_n)\in R^n$.\newline
Another formulation:
\begin{equation}
\vwi{t}=A_{t}^{-1}b_t
\label{RLS2}
\end{equation}
where $A_t=I+\sum\limits_{i=1}^{n}\vxi{i} \vxti{i}+ \vxi{t} \vxti{t}$ and $b_t=\sum\limits_{i=1}^{n}y_i\vxi{i}$ 
\end{frame}

\begin{frame}{BBQ Algorithm - Querying Labels}
We define:
\begin{equation}
r_t=\vxti{t}A_{t}^{-1}\vxi{t}
\end{equation}
\newline
\newline
A query will be issued at round $t$ if $r_t> t^{-\kappa}$.\newline
\newline
\newline
If $r_t\leq t^{-\kappa}$ the value of the label $y_t$ will remain unknown.
\end{frame}

\begin{frame}{Effect of Switch on BBQ Algorithm}
In the normal setting the BBQ algorithm works well - with logarithmic regret:
\begin{equation}
 R_T\leq O\left(d\ln{T}\right)
\end{equation}
while maintaining significantly reduced amount of quired labels:
\begin{equation}
N_T\sim dT^{\kappa}\ln{T}
\end{equation}
However as switch of the optimal classifier from $\vu$ to $\vv$ at round $\tau$ increases regret bound:
\begin{equation}
 R_T\leq O\left(\|\vv-\vu\|^2{\tau}^{2\kappa}\left(d\ln{\tau}\right)^2d\ln{T}\right)
\end{equation}
 
\end{frame}


\begin{frame}{Effect of Switch on BBQ Algorithm}
The increase in the regret bound is due to increase in the bound of the classifier's bias, after the switch:
\begin{equation}
B_t=\vwti{t}\vxi{t}-\Exp{\vwti{t}\vxi{t}}\leq r_t+\sqrt{r_t}+N_{\tau}\|\vv-\vu\|\sqrt{r_t}
\end{equation}
Instead of 
\begin{equation}
B_t=\vwti{t}\vxi{t}-\Exp{\vwti{t}\vxi{t}}\leq r_t+\sqrt{r_t}
\end{equation}
prior to the switch
\end{frame}

\begin{frame}{Using Selective Sampling to Overcome Switch}
Selective sampling concept gives us confidence on our prediction.\newline
\newline
The term $r_t$ controls and both the bias from the optimal classifier and the instantaneous regret:
\begin{itemize}
\item If $r_t$ is large, then in any case, switch or none, we can not assure low regret.
\item If $r_t$ is small, we should suffer low regret - meaning our prediction should be close enough to the optimal prediction. Unless a switch had occurred...
\end{itemize}
\end{frame}

\begin{frame}{Using Selective Sampling to Overcome Switch}
Main idea - use instances with small $r_t$ to detect switch. An "error" on such instances will be improbable and if it does occur- it must be due to a switch.\newline
\newline
But what is an "error"? - even if we know the optimal classifier $\vu$ the probability for a classification error is $\frac{1-\left|\vut\vxi{t}\right|}{2}$. So error can only be considered in terms of distance from the optimal classifier.
\newline
\newline
Problem - the optimal classifier is unknown. So how can we check if our prediction is close enough to it?

\end{frame}

\begin{frame}{Using Selective Sampling to Overcome Switch}
Solution - estimate optimal classifier $\vv$ with a demo classifier $h_t$ constructed from a window of recent instances.\newline
\begin{itemize}
\item If no switch occurred - $\vxi{t}$ and $h_t$ should give close predictions, as both are close in prediction to $\vv$.
\newline
\item If a switch occurred:
\begin{itemize}
\item If $\vxi{t}$ and $h_t$ do not yield close predictions - we detect the switch
\item If $\vxi{t}$ and $h_t$ t yield close predictions -  switch is insignificant and not much additional regret will be suffered
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Construction of Demo Classifier}
\begin{itemize}
\item Set $L_t=L_0+\sqrt{t}$
\item At round $t$  select a window of last $L_t$ instances 
\item Calculate $A_{L_t}=I+\sum\limits_{l=t-L}^{t-1}{\vxi{l}\vxti{l}}, b_{L_t}=\sum\limits_{l=t-L}^{t}y_l\vxi{l}$
\item Construct $h_t=\left(A_{L_t}+\vxi{t}\vxti{t}\right)^{-1}b_{L_t}$
\end{itemize}
To save querying labels we set resolution classifier $h_t$ for a window of $KL_t$ next instances. At round $KL_t+1$ we construct a new demo classifier, and so forth.
\end{frame}

\begin{frame}{Algorithm for Detecting Switch}
\begin{itemize}
\item Set $\delta_t=\frac{\delta}{t(t+1)}$
\item Calculate $C_t=\left\vert\vwti{t}\vxi{t}-h_{t}^{\top}\vxi{t}\right\vert$
\item Calculate: \newline \newline $K_t=\sqrt{2r_t\ln{\frac{2}{\delta_t}}}+\sqrt{2r_{L_t}\ln{\frac{2}{\delta_t}}}+r_t+\sqrt{r_t}+r_{L_t}+\sqrt{r_{L_t}}$
\item If $C_t>K_t$ declare switch and restart classifier $w_t$ from zero
\item Else continue to next round
\end{itemize}
\end{frame}


\begin{frame}{Algorithm for Detecting Switch}
\begin{itemize}
\item If $C_t>K_t$ switch is detected and we overcome its effect
\item If no switch occurred we can assure that $C_t\leq K_t$ and no false detections will be made
\item If $C_t\leq K_t$ but a switch did occur - can we assure that it will cause no significant additional regret?
\end{itemize}
First we will show that indeed if $C_t\leq K_t$ we can assure low regret.\newline
Later we will prove that the probability for a false positive is small.
\end{frame}

\begin{frame}{Regret Calculation}
The instantaneous regret is controlled by the term $|\vwti{t}\vxi{t}-\vvt\vxi{t}|$:
\begin{eqnarray}
&&R_t=\pr{y_t\vwti{t}\vxi{t}<0}-\pr{y_t\vvt\vxi{t}<0}\leq\nonumber\\
&&\varepsilon I_{\{\left|\vvt\vxi{t}\right|<\varepsilon\}}+\pr{\left|\vwti{t}\vxi{t}-\vvt\vxi{t}\right|\geq\varepsilon}
\label{regret_wt_ht1}
\end{eqnarray}
We can bound it by triangle inequality:
\begin{eqnarray}
&&\left\vert\vwti{t}\vxi{t}-\vvt\vxi{t}\right\vert\leq\left\vert\vwti{t}\vxi{t}-h_{t}^{\top}\vxi{t}\right\vert+\left\vert\vvti{t}\vxi{t}-h_{t}^{\top}\vxi{t}\right\vert\nonumber\\
&&=C_t+\left\vert\vvti{t}\vxi{t}-h_{t}^{\top}\vxi{t}\right\vert
\label{triangl_ht_wt}
\end{eqnarray}
\end{frame}

\begin{frame}{Regret Calculation}
We already have a bound for $C_t$, as a switch was not detected. What about $\left\vert\vvti{t}\vxi{t}-h_{t}^{\top}\vxi{t}\right\vert$?\newline\newline
From the bias bound on the BBQ classifier and by Hoefding bound we shall have:
\begin{equation}
\left\vert\vvt\vxi{t}-h_{t}^{\top}\vxi{t}\right\vert\leq\sqrt{2r_{L_t}\ln{\frac{2}{\delta_t}}}+r_{L_t}+\sqrt{r_{L_t}}
\label{rLt_false}
\end{equation}
With probability $1-\delta_t$.
\end{frame}



\begin{frame}{Regret Calculation}
Combining given bound on $C_t$ and equation \ref{rLt_false} we have:
\begin{eqnarray}
&&\left\vert\vwti{t}\vxi{t}-\vvt\vxi{t}\right\vert\leq\sqrt{r_t}\left(\sqrt{2\ln{\frac{2}{\delta_t}}}+1\right)+r_t\nonumber\\
&&+2\sqrt{r_{L_t}}\left(\sqrt{2\ln{\frac{2}{\delta_t}}}+1\right)+2r_{L_t}
\label{triangl_ht_wt2}
\end{eqnarray}
Equation \ref{triangl_ht_wt2} together with the identity  $I_{\{x<1\}}\leq e^{1-x}$ will allow us to bound the regret.
\end{frame}


\begin{frame}{Regret Calculation}
\begin{eqnarray}
&&\pr{\left|\vwti{t}\vxi{t}-\vvt\vxi{t}\right|\geq\varepsilon}\leq 2I_{\big\{r_{L_t}\left(\sqrt{2\ln{\frac{2}{\delta_t}}}+1\right)^2\geq\frac{\varepsilon^2}{36}\big\}}\\
&&+2I_{\big\{r_{L_t}\geq\frac{\varepsilon}{6}\big\}}+I_{\big\{r_t\left(\sqrt{2\ln{\frac{2}{\delta_t}}}+1\right)^2\geq\frac{\varepsilon^2}{36}\big\}}+I_{\big\{r_t\geq\frac{\varepsilon}{6}\big\}}\nonumber\\
&&\leq2\exp\left\{1-\frac{\varepsilon^2}{36r_{L_t}\left(\sqrt{2\ln{\frac{2}{\delta_t}}}+1\right)^2}\right\}+2\exp\left\{1-\frac{\varepsilon}{6r_{L_t}}\right\}\nonumber\\
&&+\exp\left\{1-\frac{\varepsilon^2}{36r_t\left(\sqrt{2\ln{\frac{2}{\delta_t}}}+1\right)^2}\right\}+\exp\left\{1-\frac{\varepsilon}{6r_t}\right\}\nonumber
\label{exponent_regret_class}
\end{eqnarray}
\end{frame}

\begin{frame}{Regret Calculation}
The cumulative regret is given by:
\begin{equation}
R_T=\sum\limits_{t=1}^{T}R_t
\label{cum_reg_define}
\end{equation}
We will sum over the terms of equation \ref{exponent_regret_class} to bound the regret.\newline\newline
We divide the summation to rounds where $r_t\leq t^{-\kappa}$ and rounds where $r_t\leq t^{-\kappa}$.
\end{frame}

\begin{frame}{Regret Calculation}
We use the identities:  $1-x\leq -\ln{x}$ (for $x\leq1$) and $\exp\{-x\}\leq\frac{1}{ex}$, and the fact that:
\begin{equation}
 r_t\leq 1-\frac{\det{A_{t-1}}}{\det{A_t}}
\end{equation}
to calculate the following sum:
\begin{eqnarray}
&&\sum\limits_{t=T_1,r_t> t^{-\kappa}}^{T}\exp\left\{1-\frac{\varepsilon^2}{36r_t\left(\sqrt{2\ln{\frac{2}{\delta_t}}}+1\right)^2}\right\}\leq\nonumber
\end{eqnarray}
\end{frame}
\begin{frame}{Regret Calculation}

\begin{eqnarray}
&&\leq\frac{36\left(\sqrt{2\ln{\frac{2}{\delta_T}}}+1\right)^2}{\varepsilon^2}\sum\limits_{t=T_1,r_t>t^{-\kappa}}^{T}r_t\nonumber\\
&&\leq\frac{36\left(\sqrt{2\ln{\frac{2}{\delta_T}}}+1\right)^2}{\varepsilon^2}\sum\limits_{t=T_1,r_t>t^{-\kappa}}^{T}\left(1-\frac{\det{A_{t-1}}}{\det{A_t}}\right)\nonumber\\
&&\leq -\frac{36\left(\sqrt{2\ln{\frac{2}{\delta_T}}}+1\right)^2}{\varepsilon^2}\sum\limits_{t=T_1,r_t>t^{-\kappa}}^{T}\ln{\left(\frac{\det{A_{t-1}}}{\det{A_t}}\right)}\nonumber\\
&&\leq\frac{16}{\varepsilon^2}\left\{d\ln{T}- \ln\left(\det{A_{T_1}}\right)\right\}
\label{sum_bound_rt_large2}
\end{eqnarray}

\end{frame}

\begin{frame}{Regret Calculation}
To sum over the $r_t\leq t^{-\kappa}$ bounds we use the following result: 
\begin{equation}
\int\exp\{az^r\}\,dz=-\frac{z(-az^r)^{-\frac{1}{r}}}{r}\Gamma\{\frac{1}{r},-az^r\}
\label{incomplete_gamma}
\end{equation}
This yields:
\begin{eqnarray}
&&\sum\limits_{t=T_1,r_t\leq t^{-\kappa}}^{T}\exp\left\{1-\frac{\varepsilon^2}{36r_t\left(\sqrt{2\ln{\frac{2}{\delta_t}}}+1\right)^2}\right\}=\nonumber
\end{eqnarray}
\end{frame}

\begin{frame}{Regret Calculation}
\begin{eqnarray}
&&=\sum\limits_{t=T_1,r_t\leq t^{-\kappa}}^{T}\exp\left\{1-\frac{\varepsilon^2t^{\kappa}}{36\left(\sqrt{2\ln{\frac{2}{\delta_t}}}+1\right)^2}\right\}\leq\nonumber\\
&&\leq e\int_{T_1}^{T}\exp\left\{-\frac{\varepsilon^2t^{\kappa}}{36\left(\sqrt{2\ln{\frac{2}{\delta_t}}}+1\right)^2}\right\}\,dt=\nonumber
\end{eqnarray}
\end{frame}

\begin{frame}{Regret Calculation}
\begin{eqnarray}
&&=\frac{e36^{\frac{1}{\kappa}}\left(\sqrt{2\ln{\frac{2}{\delta_t}}}+1\right)^{\frac{2}{\kappa}}}{\kappa\varepsilon^{\frac{2}{\kappa}}}\nonumber\\
&&\left[\Gamma\left\{\frac{1}{\kappa},\frac{\varepsilon^2T_{1}^{\kappa}}{36\left(\sqrt{2\ln{\frac{2}{\delta_t}}}+1\right)^2}\right\}-\Gamma\left\{\frac{1}{\kappa},\frac{\varepsilon^2T^{\kappa}}{36\left(\sqrt{2\ln{\frac{2}{\delta_t}}}+1\right)^2}\right\}\right]\nonumber
\end{eqnarray}
\newline\newline
The development of the sum $\sum\limits_{t=T_1}^{T}\exp\left\{1-\frac{\varepsilon}{6r_t}\right\}$ is identical up to constants.
\end{frame}

\begin{frame}{Regret Calculation}
We are left with summing over the $r_{L_t}$ terms.


\end{frame}
\section{Regression Analysis}

\section{Summary}








































\end{document}