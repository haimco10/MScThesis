\documentclass{beamer}

\usepackage{amssymb,amsmath,amsfonts,graphicx}
\usepackage[english]{babel}
\usepackage{graphics}
\usepackage{beamerthemesplit} 
\usepackage{beamerthemeshadow}
\usepackage[latin1]{inputenc}
\usefonttheme{professionalfonts}
\usepackage{times}
\usepackage{amsmath}
\usecolortheme{whale}
\usepackage{enumerate}
\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{times}
\usepackage{subfigure}
\usepackage{color}
\usepackage{amsbsy}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{epsfig}
\usepackage{tabulary}
\usepackage{wrapfig}
\usepackage[noadjust]{cite}
\input{prel_eli}




\usetheme{Frankfurt}


\title{Learning Drifting Data \\Using Selective Sampling}    % Enter 


\begin{document}
\maketitle
\section{Introduction}


\section{Classification Analysis}
\begin{frame}{Objectives}
Approaching the problem of shifting concept in an on-line learning classification setting we set the following objectives:
\begin{enumerate}
\item Detect the switch
\item If switch is undetected - assure that the additional regret it causes is small
\item No false detections
\end{enumerate}

\end{frame}

\begin{frame}{Problem Setting}
We work under the following assumptions:
\begin{itemize}
\item $y_t\in\{\pm1\}$
\item $\vxi{t}\in R^d$
\item for $t\leq\tau$ holds $\Exp{y_t}=\vut\vxi{t}$
\item for $t>\tau$ holds $\Exp{y_t}=\vvt\vxi{t}$
\item $\|\vxi{t}\|=\|\vu\|=\|\vv\|=1$
\end{itemize}


\end{frame}

\begin{frame}{BBQ Algorithm}
We submit prediction:
\begin{equation}
\hat{y}_t=\sign\left\{\vwti{t}\vxi{t}\right\}
\end{equation}
\newline
$\vwi{t}$ is our estimation to the optimal linear classifier obtained by solving the following problem:
\begin{equation}
\vwi{t}=\min_{\vw\in R^d}{\left\{\sum\limits_{i=1}^{n}\left(y_i-\vwt\vxi{i}\right)^2+\|\vw\|^2\right\}}
\label{RLS_prob}
\end{equation}
with $n=+N_t$ being the number of queries issued until round $t-1$
\end{frame}

\begin{frame}{BBQ Algorithm}
The solution to equation \ref{RLS_prob} is:
\begin{equation}
\vwi{t}=\left(I+S_{t-1}S_{t-1}^T+ \vxi{t} \vxti{t}\right)^{-1}S_{t-1}Y_{t-1}
\label{RLS}
\end{equation}
where $S_{t-1}=(\vxi{1},...,\vxi{n})\in R^{d\times n}$ and $Y_{t-1}=(y_1,...,y_n)\in R^n$.\newline
Another formulation:
\begin{equation}
\vwi{t}=A_{t}^{-1}b_t
\label{RLS2}
\end{equation}
where $A_t=I+\sum\limits_{i=1}^{n}\vxi{i} \vxti{i}+ \vxi{t} \vxti{t}$ and $b_t=\sum\limits_{i=1}^{n}y_i\vxi{i}$ 
\end{frame}

\begin{frame}{BBQ Algorithm - Querying Labels}
We define:
\begin{equation}
r_t=\vxti{t}A_{t}^{-1}\vxi{t}
\end{equation}
\newline
\newline
A query will be issued at round $t$ if $r_t> t^{-\kappa}$.\newline
\newline
\newline
If $r_t\leq t^{-\kappa}$ the value of the label $y_t$ will remain unknown.
\end{frame}

\begin{frame}{Effect of Switch on BBQ Algorithm}
In the normal the BBQ algorithm works well - with logarithmic regret:
\begin{equation}
 R_T\leq O\left(d\ln{T}\right)
\end{equation}
while maintaining significantly reduced amount of quired labels:
\begin{equation}
N_T\sim dT^{\kappa}\ln{T}
\end{equation}
However as switch of the optimal classifier from $\vu$ to $\vv$ at round $\tau$ increases regret bound:
\begin{equation}
 R_T\leq O\left(\|\vv-\vu\|^2{\tau}^{2\kappa}\left(d\ln{\tau}\right)^2d\ln{T}\right)
\end{equation}
 
\end{frame}


\begin{frame}{Effect of Switch on BBQ Algorithm}
The increase in the regret bound is due to increase in the bound of the classifier's bias, after the switch:
\begin{equation}
B_t=\vwti{t}\vxi{t}-\Exp{\vwti{t}\vxi{t}}\leq r_t+\sqrt{r_t}+N_{\tau}\|\vv-\vu\|\sqrt{r_t}
\end{equation}
Instead of 
\begin{equation}
B_t=\vwti{t}\vxi{t}-\Exp{\vwti{t}\vxi{t}}\leq r_t+\sqrt{r_t}
\end{equation}
prior to the switch
\end{frame}

\begin{frame}{Using Selective Sampling to Overcome Switch}
Selective sampling concept gives us confidence on our prediction.\newline
\newline
The term $r_t$ controls and the bias and the instantaneous regret:
\begin{itemize}
\item If $r_t$ is large, then in any case, switch or none, we can not assure low regret.
\item If $r_t$ is small, we should suffer low regret - meaning our prediction should be close enough to the optimal prediction. Unless a switch had occurred...
\end{itemize}
\end{frame}

\begin{frame}{Using Selective Sampling to Overcome Switch}
Main idea - use instances with small $r_t$ to detect switch. An "error" on such instance will be improbable and if it does occur- it must be due to a switch.\newline
\newline
But what is an "error" - even if we know the optimal classifier $\vu$ the probability for a classification error is $\frac{1-\left|\vut\vxi{t}\right|}{2}$. So error can only be considered in terms of distance from the optimal classifier.
\newline
\newline
Problem - the optimal classifier is unknown. So how can we check if our prediction is close enough to it?

\end{frame}

\begin{frame}{Using Selective Sampling to Overcome Switch}
Solution - estimate optimal classifier $\vv$ with a demo classifier $h_t$ constructed from recent instances.\newline
\begin{itemize}
\item If no switch occurred - $\vxi{t}$ and $h_t$ should give close predictions, as both are close in prediction to $\vv$.
\newline
\item If a switch occurred:
\begin{itemize}
\item If $\vxi{t}$ and $h_t$ do not yield close predictions - we detect the switch
\item If $\vxi{t}$ and $h_t$ t yield close predictions -  switch is insignificant and not much additional regret will be suffered
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Construction of Demo Classifier}
\begin{itemize}
\item Set $L_t=L_0+\sqrt{t}$
\item At round $t$  select a window of last $L_t$ instances 
\item Set $A_{L_t}=I+\sum\limits_{l=t-L}^{t-1}{\vxi{l}\vxti{l}}, b_{L_t}=\sum\limits_{l=t-L}^{t}y_l\vxi{l}$
\item Construct $h_t=\left(A_{L_t}+\vxi{t}\vxti{t}\right)^{-1}b_{L_t}$
\end{itemize}
To save querying labels we set resolution classifier $h_t$ for a window of $KL_t$ next instances. At round $KL_t+1$ we construct a new demo classifier, and so forth.
\end{frame}

\begin{frame}{Algorithm for Detecting Switch}
\begin{itemize}
\item Set $\delta_t=\frac{\delta}{t(t+1)}$
\item Calculate $C_t=\vert\vwti{t}\vxi{t}-h_{t}^{\top}\vxi{t}\vert$
\item Calculate: \newline \newline $K_t=\sqrt{2r_t\ln{\frac{2}{\delta_t}}}+\sqrt{2r_{L_t}\ln{\frac{2}{\delta_t}}}+r_t+\sqrt{r_t}+r_{L_t}+\sqrt{r_{L_t}}$
\item If $C_t>K_t$ declare switch and restart classifier $w_t$ from zero
\item Else continue to next round
\end{itemize}
\end{frame}


\begin{frame}{Algorithm for Detecting Switch}
\begin{itemize}
\item If $C_t>K_t$ switch is detected and we overcome its effect
\item If no switch occurred we can assure that $C_t\leq K_t$ and no false detections will be made
\item If $C_t\leq K_t$ but a switch did occur - can we assure that it will cause no significant additional regret?
\end{itemize}
First we will show that indeed if $C_t\leq K_t$ we can assure low regret.\newline
Later we will prove that the probability for a false positive is small.
\end{frame}

\begin{frame}{Regret Calculation}
The regret is controlled by the term $|\vwti{t}\vxi{t}-\vvt\vxi{t}|$:
\begin{eqnarray}
&&R_t=\pr{y_t\vwti{t}\vxi{t}<0}-\pr{y_t\vvt\vxi{t}<0}\leq\nonumber\\
&&\varepsilon I_{\{|\vvt\vxi{t}|<\varepsilon\}}+\pr{|\vwti{t}\vxi{t}-\vvt\vxi{t}|\geq\varepsilon}
\label{regret_wt_ht1}
\end{eqnarray}
We can bound it by triangle inequality:
\begin{eqnarray}
&&\vert\vwti{t}\vxi{t}-\vvt\vxi{t}\vert\leq\vert\vwti{t}\vxi{t}-h_{t}^{\top}\vxi{t}\vert+\vert\vvti{t}\vxi{t}-h_{t}^{\top}\vxi{t}\vert\nonumber\\
&&=C_t+\vert\vvti{t}\vxi{t}-h_{t}^{\top}\vxi{t}\vert
\label{triangl_ht_wt}
\end{eqnarray}
\end{frame}

\begin{frame}{Regret Calculation}
We already have a bound for $C_t$, as a switch was not detected. What about $\vert\vvti{t}\vxi{t}-h_{t}^{\top}\vxi{t}\vert$?\newline\newline
From the bias bound on the BBQ classifier and by Hoefding bound we shall have:
\begin{equation}
\vert\vvt\vxi{t}-h_{t}^{\top}\vxi{t}\vert\leq\sqrt{2r_{L_t}\ln{\frac{2}{\delta_t}}}+r_{L_t}+\sqrt{r_{L_t}}
\label{rLt_false}
\end{equation}
With probability $1-\delta_t$.
\end{frame}



\begin{frame}{Regret Calculation}
Combining given bound on $C_t$ and equation \ref{rLt_false} we have:
\begin{eqnarray}
&&\vert\vwti{t}\vxi{t}-\vvt\vxi{t}\vert\leq\sqrt{r_t}\left(\sqrt{2\ln{\frac{2}{\delta_t}}}+1\right)+r_t\nonumber\\
&&+2\sqrt{r_{L_t}}\left(\sqrt{2\ln{\frac{2}{\delta_t}}}+1\right)+2r_{L_t}
\label{triangl_ht_wt2}
\end{eqnarray}
Equation \ref{triangl_ht_wt2} together with the identity  $I_{\{x<1\}}\leq e^{1-x}$ will allow us to bound the regret.
\end{frame}


\begin{frame}{Regret Calculation}
\begin{eqnarray}
&&\pr{|\vwti{t}\vxi{t}-\vvt\vxi{t}|\geq\varepsilon}\leq 2I_{\big\{\big(2r_{L_t}\ln{\frac{2}{\delta_t}}\big)\geq\frac{\varepsilon^2}{81}\big\}}\\
&&+2I_{\big\{r_{L_t}\geq\frac{\varepsilon}{9}\big\}}+2I_{\{r_{L_t}\geq\frac{\varepsilon^2}{81}\big\}}\nonumber\\
&&+I_{\big\{\big(2r_t\ln{\frac{2}{\delta_t}}\big)\geq\frac{\varepsilon^2}{81}\big\}}+I_{\big\{r_t\geq\frac{\varepsilon}{9}\big\}}+I_{\big\{r_t\geq\frac{\varepsilon^2}{81}\big\}}\nonumber\\
&&\leq\exp\{1-\frac{\varepsilon^2}{81\big(2r_t\ln{\frac{2}{\delta_t}}\big)}\}+\exp\{1-\frac{\varepsilon}{9r_t}\}+\exp\{1-\frac{\varepsilon^2}{81r_t}\}\nonumber\\
&&+2\exp\{1-\frac{\varepsilon^2}{81\big(2r_{L_t}\ln{\frac{2}{\delta_t}}\big)}\}+2\exp\{1-\frac{\varepsilon}{9r_{L_t}}\}+2\exp\{1-\frac{\varepsilon^2}{81r_{L_t}}\}\nonumber
\label{exponent_regret_class}
\end{eqnarray}
\end{frame}


\begin{frame}{Regret Calculation}
\begin{eqnarray}
&&\pr{|\vwti{t}\vxi{t}-\vvt\vxi{t}|\geq\varepsilon}\leq 2I_{\big\{\big(r_{L_t}\left(\sqrt{2\ln{\frac{2}{\delta_t}}}+1\right)\ln{\frac{2}{\delta_t}}\big)\geq\frac{\varepsilon^2}{36}\big\}}\\
&&+2I_{\big\{r_{L_t}\geq\frac{\varepsilon}{9}\big\}}+2I_{\{r_{L_t}\geq\frac{\varepsilon^2}{81}\big\}}\nonumber\\
&&+I_{\big\{\big(2r_t\ln{\frac{2}{\delta_t}}\big)\geq\frac{\varepsilon^2}{81}\big\}}+I_{\big\{r_t\geq\frac{\varepsilon}{9}\big\}}+I_{\big\{r_t\geq\frac{\varepsilon^2}{81}\big\}}\nonumber\\
&&\leq\exp\{1-\frac{\varepsilon^2}{81\big(2r_t\ln{\frac{2}{\delta_t}}\big)}\}+\exp\{1-\frac{\varepsilon}{9r_t}\}+\exp\{1-\frac{\varepsilon^2}{81r_t}\}\nonumber\\
&&+2\exp\{1-\frac{\varepsilon^2}{81\big(2r_{L_t}\ln{\frac{2}{\delta_t}}\big)}\}+2\exp\{1-\frac{\varepsilon}{9r_{L_t}}\}+2\exp\{1-\frac{\varepsilon^2}{81r_{L_t}}\}\nonumber
\label{exponent_regret_class}
\end{eqnarray}
\end{frame}
























\section{Regression Analysis}

\section{Summary}








































\end{document}