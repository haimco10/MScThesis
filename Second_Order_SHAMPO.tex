\chapter{Second Order SHAMPO}

% \section{second order aggressive}
% 
%   \begin{algorithmic}
%     \State \textbf{Parameters:}  $c\in\mathbb{R}>0$.\\ 
%     \State \textbf{Initialize:} $\vwi{i,0}=\vzero$, $A_0=I$ \\
%     \For {$t=1,2, ..., n$} 
%       
% \begin{enumerate}
% \nolineskips
% \item Observe $K$ instance vectors, $\vxiit$, ($i=1 \comdots K$).
% \item Compute  $\hat{p}_{i,t}=\vxiit^T \paren{A_{i,t-1}+\vxiit\vxiit^T}^{-1}\vw_{i,t-1}$.
% \item Predict $K$ labels, $\hyi{i,t}=\sign(\hat{p}_{i,t})$.
% \item Compute $r_i = \vxiit^T A_{i,t-1}^{-1}\vxiit$.
% \item Draw problem $J_t$  with the distribution:
% \begin{align}
% \pr{J_t=j} &=
% \frac{1}{D_{t}}\frac{2c}{2c+\paren{\Theta\paren{\abs{\hat{p}_{j,t}},r_{j,t}}}_+}, \nonumber\\
% D_t &=2c
% \sum_i \paren{2c+\paren{\Theta\paren{\abs{\hat{p}_{i,t}},r_{i,t}}}_+}^{-1}. \nonumber
% \end{align}
% %Where $m,i\in\{1,...,K\}$ and $D_t$ is the normalization factor. Set $Z_{J,t}=1,~Z_{i,t}=0 , ~\forall i\ne J $.
% If  \Theta\paren{\abs{\hat{p}_{J_t,t}},r_{i,t}}\ge0 \Then
%         
%         if $y_{J_t,t}\ne{\hat{y}_{J_t,t}$ set $U_{J_t,t}=1$.
%         
%         end if 
% 
% else
% 
% set $U_{J_t,t}=1$.
% 
% end if.
% 
% \item Update:
% \begin{align}
% &\vwi{J_t,t} = \vwi{J_t,t-1}+U_{J_t,t}\,  \vxi{J_t,t}  \yi{J_t,t}\,\label{perc_update}\\
% &A_{J_t,t}=A_{J_t,t-1}+ U_{J_t,t}\vxi{J_t,t}\vxi{J_t,t}^T\nonumber
% \end{align}
% \end{enumerate}
% \EndFor  
% \State {\bf Output}: $\vwi{i,n}$ for $i=1 \comdots K$.
% \end{algorithmic}\\

% \caption{Second order aggressive SHAMPO. \label{alg:SHAMPO}}
% \end{figure}        
%\end{algorithm}


This algorithm and proof builds on the second order selective sampling by Cesa-Bianchi et al ~\cite{cesa2006worst} define the function
\begin{equation}
\Theta\paren{\abs{\hat{p}_{i,t}},r_{i,t}}=\paren{1+r_{i,t}}\hat{p}_{i,t}^2+2\abs{\hat{p}_{i,t}}-\frac{r_{i,t}}{1+r_{i,t}}
\end{equation}

In order to understand the way that the aggressive update works, there is a need to examine the function $\Theta\paren{\abs{\hat{p}_{i,t}},r_{i,t}}$. One can see that this function is quadratic in $\hat{p}_{i,t}$ , such that it becomes negative in a close interval. Solving this quadratic form, shows that 
\begin{equation}
\Theta\paren{\abs{\hat{p}_{i,t}},r_{i,t}}\le0 \Leftrightarrow \abs{\hat{p}_{i,t}}\le\theta({r_{i,t}})=\frac{-1+\sqrt{1+r_{i,t}}}{1+r_{i,t}}.
\end{equation}
 The last equation shows that the condition on the function $\Theta\paren{\abs{\hat{p}_{j,t}},r_{j,t}}$ can be translated to threshold on the margin. First, a task is chosen according to the distribution above, then, for margin that is less the threshold, an aggressive update will be issued whereas for margin that is bigger than that, the algorithm will performed update only when there is a prediction error. For 
all the rest of the task that were not chosen, no update is issued. For now, we would like to analyse the possibilities for one task in a certain iteration. There are two extreme cases: First, when the the algorithm has not get yet input examples the similar to the current one, which cause the maximal uncertainty i.e., $r_{i,t}=1$. In this case,  the aggressiveness threshold is maximal as well, and we get $\max{\theta({r_{i,t}})}=\frac{-1+\sqrt{2}}{2}\approx0.21$ and an aggressive update will be issued only when the margin is less than this value. Another interesting case is when we saw the same example many times before, such the uncertainty in the prediction now is relatively low, which means $r_{i,t}\approx0$. In this scenario, the aggressive update will be issued only when the margin is zero, $\hat{p}_{i,t}=0$. 
\\

\begin{proof} 
\\ 
Before proofing the Thm. we will use the next inequality. define $x\in[0,1]$
\begin{equation}
\sqrt{1-x}+\sqrt{1+x}\le2.
\label{technical_inequality}
\end{equation}
From the concavity of $\sqrt{1+x}$ we see that $\sqrt{1+x}\le1+\half x$. using this inequality twice, we get $\sqrt{1-x}+\sqrt{1+x}\le1-\half x+1+\half x=2$.

Define 
\begin{equation*}
\Phi_{i,t}(\vu_i)=\half\normt{\vu_i}+\half\sum_{s=1}^{t}{Z_{i,t}U_{i,t}\paren{y_{i,t}-\vu_i^T\vx_{i,t}}}^2
\end{equation*}
Simlar to the proof of Thm .3 of Cesa-Bianchi et al ~\cite{cesa2006worst} and Forster ????,
\begin{equation*}
\begin{split}
\half Z_{i,t}U_{i,t}\paren{y_{i,t}-\hat{p}_{i,t}}^{2}= &\inf_{\vu_i}{\Phi_{i,t+1}}(\vu_i)-\inf_{\vu_i}{\Phi_{i,t}}(\vu_i)+\frac{Z_{i,t}U_{i,t}}{2}\vxiit^TA_{i,t}^{-1}\vxiit\\
&-\frac{Z_{i,t}U_{i,t}}{2}\vxiit^TA_{i,t-1}^{-1}\vxiit\hat{p}_{i,t}^2\\
=&\inf_{\vu_i}{\Phi_{i,t+1}}(\vu_i)-\inf_{\vu_i}{\Phi_{i,t}}(\vu_i)+\frac{Z_{i,t}U_{i,t}}{2}\frac{r_{i,t}}{1+r_{i,t}}-\frac{Z_{i,t}U_{i,t}}{2}r_{i,t}\hat{p}_{i,t}^2
\end{split}
\end{equation*} 
Now, we sum up the equation over $t$,
 
\begin{equation*}
\begin{split}
\half \sum_{t=1}^{n}Z_{i,t}U_{i,t}\paren{y_{i,t}-\hat{p}_{i,t}}^{2}=& \inf_{\vu_i}{\Phi_{i,n+1}}(\vu_i)+ \sum_{t=1}^{n}\frac{Z_{i,t}U_{i,t}}{2}\frac{r_{i,t}}{1+r_{i,t}}-\sum_{t=1}^{n}\frac{Z_{i,t}U_{i,t}}{2}r_{i,t}\hat{p}_{i,t}^2\\
\le&\half\normt{\vu_i}+\half\sum_{t=1}^{n}{Z_{i,t}U_{i,t}\paren{y_{i,t}-\vu_i^T\vx_{i,t}}}^2+ \sum_{t=1}^{n}\frac{Z_{i,t}U_{i,t}}{2}\frac{r_{i,t}}{1+r_{i,t}}\\&-\sum_{t=1}^{n}\frac{Z_{i,t}U_{i,t}}{2}r_{i,t}\hat{p}_{i,t}^2.
\end{split}
\end{equation*} 
For simplification we will define
\begin{equation*}
A_{i,n}=I+\sum_{t=1}^{n}{Z_{i,t}U_{i,t}}\vxiit\vxiit^T.
\end{equation*}
Expanding the squares we get,
\begin{equation}
\begin{split}
\half \sum_{t=1}^{n}Z_{i,t}U_{i,t}&\paren{\hat{p}_{i,t}^2-2y_{i,t}\hat{p}_{i,t}-\frac{r_{i,t}}{1+r_{i,t}}+r_{i,t}\hat{p}_{i,t}^2}\\
\le& \half\normt{\vu_i}+\sum_{t=1}^{n}{Z_{i,t}U_{i,t}\vu_i^T\vx_{i,t}\vx_{i,t}^T\vu_i}-\sum_{t=1}^{n}{Z_{i,t}U_{i,t}\vu_i^T\vx_{i,t}y_{i,t}}\\
&=\half \vu_i^T\paren{I+\sum_{t=1}^{n}{Z_{i,t}U_{i,t}}\vxiit\vxiit^T}\vu_i-\sum_{t=1}^{n}{Z_{i,t}U_{i,t}\vu_i^T\vx_{i,t}y_{i,t}}\\
&=\half \vu_i^T A_{i,n} \vu_i-\sum_{t=1}^{n}{Z_{i,t}U_{i,t}\vu_i^T\vx_{i,t}y_{i,t}}.
\end{split}
\label{sec_order_1}
\end{equation} 
The vectors $\vu_i$ can be replaced with their scaled version, $c\vu_i$. introducing the trivial inequality, $1-x\le \max\braces{1-x,0}$ we get 
\begin{equation}
\begin{split}
cZ_{i,t}U_{i,t}\paren{1-\vu_i^T\vx_{i,t}y_{i,t}} \le cZ_{i,t}U_{i,t}\max\braces{1-\vu_i^T\vx_{i,t}y_{i,t},0}\\
-cZ_{i,t}U_{i,t}\vu_i^T\vx_{i,t}y_{i,t}\le-cZ_{i,t}U_{i,t}+c \lossp{}\paren{\vu_i^T\vx_{i,t}y_{i,t}}.
\label{sec_order_2}
\end{split}
\end{equation}
Rearranging an plugging \eqref{sec_order_2} and \eqref{sec_order_1} 

\begin{equation}
\begin{split}
\half \sum_{t=1}^{n}Z_{i,t}U_{i,t}&\paren{\hat{p}_{i,t}^2-2y_{i,t}\hat{p}_{i,t}-\frac{r_{i,t}}{1+r_{i,t}}+r_{i,t}\hat{p}_{i,t}^{2}+2c}\\
&\le\frac{c^2}{2} \vu_i^T A_{i,n} \vu_i+c\sum_{t=1}^{n}{Z_{i,t}U_{i,t}\lossp{}\paren{\vu_i^T\vx_{i,t}y_{i,t}}}
\label{sec_order_2}
\end{split}
\end{equation}
Recall that $U_{i,t}=M_{i,t}+G_{i,t}$ we will split the inequality into two different cases. First we will take into consideration the cases when an error update was performed, i.e.$M_{i,t}=1$, in which we have $-y_{i,t}\hat{p}_{i,t}=\abs{\hat{p}_{i,t}}$. In this case we need to consider also two subcases, when $\Theta\paren{\abs{\hat{p}_{i,t}},r_{i,t}}\ge0$   and when $\Theta\paren{\abs{\hat{p}_{i,t}},r_{i,t}}<0$. Beginning with the former subcase, recall that for this case 
$\mathbb{E}_{t-1}\brackets{Z_{i,t}}=\frac{1}{D_{t}}\frac{2c}{2c+\paren{\Theta\paren{\abs{\hat{p}_{j,t}},r_{j,t}}}}$, we get 
\begin{equation*}
\begin{split}
\mathbb{E}&\brackets{Z_{i,t}U_{i,t}\paren{\hat{p}_{i,t}^2-2y_{i,t}\hat{p}_{i,t}-\frac{r_{i,t}}{1+r_{i,t}}+r_{i,t}\hat{p}_{i,t}^{2}+2c}}\\
&=\mathbb{E}\brackets{\mathbb{E}_{t-1}\brackets{Z_{i,t}}U_{i,t}\paren{\hat{p}_{i,t}^2-2y_{i,t}\hat{p}_{i,t}-\frac{r_{i,t}}{1+r_{i,t}}+r_{i,t}\hat{p}_{i,t^{}}^{2}+2c}}\\
&=2c\mathbb{E}\brackets{\frac{1}{D_t}U_{i,t}}.
\end{split}
\end{equation*}
When $\Theta\paren{\abs{\hat{p}_{i,t}},r_{i,t}}<0$  the conditional expectation becomes $\mathbb{E}_{t-1}\brackets{Z_{i,t}}=\frac{1}{D_t}$ and the thus,
\begin{equation*}
\begin{split}
\mathbb{E}&\brackets{Z_{i,t}U_{i,t}\paren{\hat{p}_{i,t}^2-2y_{i,t}\hat{p}_{i,t}-\frac{r_{i,t}}{1+r_{i,t}}+r_{i,t}\hat{p}_{i,t}^{2}+2c}}\\
&=\mathbb{E}\brackets{\mathbb{E}_{t-1}\brackets{Z_{i,t}}U_{i,t}\paren{\hat{p}_{i,t}^2+2\abs{\hat{p}_{i,t}}-\frac{r_{i,t}}{1+r_{i,t}}+r_{i,t}\hat{p}_{i,t}^{2}+2c}}\\
&\ge\mathbb{E}\brackets{\mathbb{E}_{t-1}\brackets{Z_{i,t}}U_{i,t}\paren{-\frac{r_{i,t}}{1+r_{i,t}}+2c}}\\
&\ge 2c \mathbb{E}\brackets{\frac{1}{D_t}U_{i,t}}-\frac{r_{i,t}}{1+r_{i,t}}\mathbb{E}\brackets{\frac{1}{D_t}}.
\end{split}
\end{equation*}
Now we examine the case where an update was performed, but there was no mistake. In this case, $0\le y_{i,t}\hat{p}_{i,t}$ and the aggressive update was performed. Recall the bound on the margin for such case and using \eqref{sec_order_2} ,
we bound the margin as follows\begin{equation*}
0\le y_{i,t}\hat{p}_{i,t}\le \theta({r_{i,t}})=\frac{-1+\sqrt{1+r_{i,t}}}{1+r_{i,t}}.
\end{equation*}
We can bound now,
\begin{equation*}
\begin{split}
\hat{p}_{i,t}^2&-2y_{i,t}\hat{p}_{i,t}-\frac{r_{i,t}}{1+r_{i,t}}+r_{i,t}\hat{p}_{i,t}^{2}+2c\\
&=(1+r_{i,t})\hat{p}_{i,t}^2-2y_{i,t}\hat{p}_{i,t}+\frac{r_{i,t}}{1+r_{i,t}}-2\frac{r_{i,t}}{1+r_{i,t}}+2c\\
&=f(y_{i,t}\hat{p}_{i,t})-2\frac{r_{i,t}}{1+r_{i,t}}+2c
\end{split}
\end{equation*}
\end{proof}          
where $f(y_{i,t}\hat{p}_{i,t})=(1+r_{i,t})\hat{p}_{i,t}^2-2y_{i,t}\hat{p}_{i,t}+\frac{r_{i,t}}{1+r_{i,t}}$ is a quadratic convex function with two non-negative roots $\frac{1\pm\sqrt{1-r_{i,t}}}{1+r_{i,t}}$ and we know that the margin is lower than the smaller root , $y_{i,t}\hat{p}_{i,t}\le\frac{1-\sqrt{1-r_{i,t}}}{1+r_{i,t}}$ which leads to the inequality $f(y_{i,t}\hat{p}_{i,t})\ge0$ so we bound 
\begin{equation*}
\begin{split}
\mathbb{E}&\brackets{Z_{i,t}U_{i,t}\paren{\hat{p}_{i,t}^2-2y_{i,t}\hat{p}_{i,t}-\frac{r_{i,t}}{1+r_{i,t}}+r_{i,t}\hat{p}_{i,t}^{2}+2c}}\\
&=\mathbb{E}\brackets{\mathbb{E}_{t-1}\brackets{Z_{i,t}}U_{i,t}\paren{f(y_{i,t}\hat{p}_{i,t})-2\frac{r_{i,t}}{1+r_{i,t}}+2c}}\\
&\ge\mathbb{E}\brackets{\mathbb{E}_{t-1}\brackets{Z_{i,t}}U_{i,t}\paren{-2\frac{r_{i,t}}{1+r_{i,t}}+2c}}\\
&\ge 2c\mathbb{E}\brackets{\frac{1}{D_t}U_{i,t}}-\frac{2r_{i,t}}{1+r_{i,t}}\mathbb{E}\brackets{\frac{1}{D_t}\frac{2r_{i,t}}{1+r_{i,t}}}.
\end{split}
\end{equation*}
Summarize the results we get,
\begin{equation}
\begin{split}
\half \sum_{t=1}^{n}&\mathbb{E}\brackets{Z_{i,t}U_{i,t}\paren{\hat{p}_{i,t}^2-2y_{i,t}\hat{p}_{i,t}-\frac{r_{i,t}}{1+r_{i,t}}+r_{i,t}\hat{p}_{i,t}^{2}+2c}}\\
&\ge c \sum_{t\in\mathcal{M}}\mathbb{E}\brackets{\frac{1}{D_t}U_{i,t}}+c \sum_{t\in\mathcal{G}}\mathbb{E}\brackets{\frac{1}{D_t}U_{i,t}}\\
&-\half\sum_{t\in\mathcal{A\cap M}}\frac{r_{i,t}}{1+r_{i,t}}\mathbb{E}\brackets{\frac{1}{D_t}}
-\sum_{t\in\mathcal{A\cap G}}\frac{r_{i,t}}{1+r_{i,t}}\mathbb{E}\brackets{\frac{1}{D_t}}
\end{split}
\end{equation}
Combining the result of the last inequality with the expectation of the  \eqref{sec_order_2}, recall that  $\sum_{t\in\mathcal{M}}U_{i,t}=M_i$ , and  $\sum_{t\in\mathcal{G}}U_{i,t}=G_i$ we get,   
\begin{equation*}
\begin{split}
c \sum_{t\in\mathcal{M}}\mathbb{E}\brackets{\frac{1}{D_t}U_{i,t}}+c \sum_{t\in\mathcal{G}}\mathbb{E}&\brackets{\frac{1}{D_t}U_{i,t}}
-\frac{1}{2c}\sum_{t\in\mathcal{A\cap M}}\frac{r_{i,t}}{1+r_{i,t}}\mathbb{E}\brackets{\frac{1}{D_t}}\\
-\frac{1}{c}\sum_{t\in\mathcal{A\cap U}}\frac{r_{i,t}}{1+r_{i,t}}\mathbb{E}\brackets{\frac{1}{D_t}}
\le& \frac{c}{2} \vu_i^T \mathbb{E}\brackets{A_{i,n}} \vu_i+\sum_{t=1}^{n}\mathbb{E}\brackets{{Z_{i,t}U_{i,t}\lossp{}\paren{\vu_i^T\vx_{i,t}y_{i,t}}}}
\end{split}
\end{equation*}

The normalization can also been bound by
\begin{equation*}
\begin{split}
D_{t}=2c\sum_{i=1}^{K}{\left({2c+\paren{\Theta\paren{\abs{\hat{p}_{i,t}},r_{i,t}}}_+}\right)^{-1}}& \le  2c\sum_{m=1}^{K}{\frac{1}{2c}}=K
\end{split}
\end{equation*}
which leads to


\begin{equation*}
\begin{split}
\mathbb{E}\brackets{M_{i}}+ &\mathbb{E}\brackets{G_{i}}
-\frac{1}{2c}\mathbb{E}\sum_{t\in\mathcal{A\cap M}}\brackets{\frac{r_{i,t}}{1+r_{i,t}}}
-\frac{1}{c}\mathbb{E}\sum_{t\in\mathcal{A\cap U}}\brackets{\frac{r_{i,t}}{1+r_{i,t}}}\\
\le& \frac{Kc}{2} \vu_i^T \mathbb{E}\brackets{A_{i,n}} \vu_i+K\sum_{t=1}^{n}\mathbb{E}\brackets{{Z_{i,t}U_{i,t}\lossp{}\paren{\vu_i^T\vx_{i,t}y_{i,t}}}}
\end{split}
\end{equation*}



\begin{equation*}
\begin{split}
\mathbb{E}\brackets{M_{i}}\le&\frac{Kc}{2} \vu_i^T \mathbb{E}\brackets{A_{i,n}} \vu_i+K\sum_{t=1}^{n}\mathbb{E}\brackets{{Z_{i,t}U_{i,t}\lossp{}\paren{\vu_i^T\vx_{i,t}y_{i,t}}}} -\mathbb{E}\brackets{G_{i}}\\
&+\frac{1}{2c}\mathbb{E}\sum_{t\in\mathcal{A\cap M}}\brackets{\frac{r_{i,t}}{1+r_{i,t}}}
+\frac{1}{c}\mathbb{E}\sum_{t\in\mathcal{A\cap U}}\brackets{\frac{r_{i,t}}{1+r_{i,t}}}\\
\le& \frac{Kc}{2} \vu_i^T \mathbb{E}\brackets{A_{i,n}} \vu_i+K\mathbb{E}\brackets{\sum_{t=1}^{n}{Z_{i,t}U_{i,t}\lossp{}\paren{\vu_i^T\vx_{i,t}y_{i,t}}}}-\mathbb{E}\brackets{G_{i}}\\
&+\frac{1}{c}\sum_{t\in\mathcal{A}}\brackets{\frac{r_{i,t}}{1+r_{i,t}}}
\end{split}
\end{equation*}
Now, we can summarize the inequality over all of the tasks,
\begin{equation*}
\begin{split}
\mathbb{E}\brackets{M}\le &\frac{cK}{2}\sum_{i=1}^{K}  \vu_i^T \mathbb{E}\brackets{A_{i,n}} \vu_i+K\mathbb{E}\brackets{\sum_{i=1}^{K}\sum_{t=1}^{n}Z_{i,t}U_{i,t}{\lossp{}\paren{\vu_i^T\vx_{i,t}y_{i,t}}}}-\mathbb{E}\brackets{G}\\
&+\frac{1}{c}\mathbb{E}\sum_{i=1}^{K}\sum_{t\in\mathcal{A}}\brackets{\frac{r_{i,t}}{1+r_{i,t}}}
\end{split}
\end{equation*}
 
\begin{equation*}
\begin{split}
\mathbb{E}\brackets{M}\le &\frac{cK}{2}\sum_{i=1}^{K}  \vu_i^T \mathbb{E}\brackets{A_{i,n}} \vu_i+K{\bar L}_{1,n}-\mathbb{E}\brackets{G}\\
&+\frac{1}{c}\mathbb{E}\sum_{i=1}^{K}\sum_{t\in\mathcal{A}}\brackets{\frac{r_{i,t}}{1+r_{i,t}}}
\end{split}
\end{equation*} 
 \section{From Multi-task to Contextual Bandits}
Although our algorithm is designed for many binary-classification tasks that can be independent, it can also be applied in two settings of contextual bandits, when one decoupling exploration and exploitation is allowed in every cycle~\cite{DBLP:conf/icml/YuM09,DBLP:conf/icml/AvnerMS12}. The problem of this setting is predicting a label $\hat{Y}_t \in\{ 1 \comdots C\}$ given an input $\vxi{t}$. As before, the algorithm works in rounds. On round $t$ the algorithm receives an input $\vxi{t}$ and outputs  multicalss label $\hat{Y}_t\in\{1 \comdots C\}$. Then, it queries for some information about the label via a single binary ``yes-no'' question, and uses the feedback to update its model. We consider here two forms of binary questions.

\subsection{One-vs-Rest}
In the first setting, termed {\em one-vs-rest}, the algorithm asks if the true label is some label $\bar{Y}_t\in\{ 1 \comdots C\}$, possibly not the predicted label, i.e. it may be the case that $\bar{Y}_t \neq\hat{Y}_t$. Given the response whether  $\bar{Y}_t$ is indeed the true label $Y_t$, the algorithm updates its models. The reduction we perform is by introducing $K$ tasks to be done in parallel, one per class, such that $K=C$. The $i^{\text{th}}$ task is to decide whether the true label of the current input  $\vx_t$ is class $i$ or not. Even though, for the most of the tasks, we can not deduce the true labeling $Y_t\in\{ 1 \comdots C\}$,  considering a single task prediction (actually it can be done only for one  specific task at a time),  still the binary prediction, gives us the ability to eliminate one of the classes. For example: in the case of numbers OCR, if the true label of an input image is $6$, the first task is asking if the predicted label should be $0$ or not, the answer of this question is indeed negative, so  the true label may not be $0$, but we still don't know what it is. Given the output of all (binary) classifiers, the algorithm generates a single multi-class prediction to be the single label for which the output of the corresponding binary classifier is positive.  If such class does not exist, or there are more than one such classes, a random prediction is used, that is, given an input $\vxi{t}$ we define $\hat{Y}_t = \arg\max_i \hat{p}_{i,t}$, where ties are broken arbitrarily   . Given the feedback whether  $\bar{Y}_t$ is indeed the true label $Y_t$, the algorithm updates its models. The label to be queried is $\bar{Y}_t=J_t$, i.e. the problem index that SHAMPO is querying. We now analyze the performance of this reduction as a multiclass prediction algorithm.
\begin{corollary} 
Assume the SHAMPO algorithm is executed as above with $K=C$ one-vs-rest tasks, on a sequence $(\vx_1,Y_1),...(\vx_n,Y_n)\in\mathbb{R}^d\times\{1,...,C\}$, and input parameter $b>0$. Then for all $\gamma>0$ and all $\vui{i}\in\mathbb{R}^d$, the expected number of multi-class errors is bounded as follows
\begin{displaymath}
\mathbb{E}\brackets{\sum_t \1{Y_t \neq \hat{Y}_t}}\le \frac{C}{\gamma}\brackets{\paren{1+\frac{X^2}{2b} }{\bar L}_{\gamma,n}+\frac{\paren{{2b+X^2}}^2U^2}{8{\gamma}b}}~,
\end{displaymath}
where $\1{A}=1$ if the predicate $A$ is true, and zero otherwise.
\end{corollary}
The corollary follows directly from \thmref{thm:bound} by noting that, $\1{Y_t \neq \hat{Y}_t} \leq \sum_i M_{i,t}$. That is, there is a multiclass mistake if there is at least one prediction mistake of one of the one-vs-rest problems. The closest setting  to the presented setting is the one of contextual bandits, yet we allow decoupling of exploration and exploitation. Ignoring this decoupling, the Banditron algorithm~\cite{kakade2008efficient} is the closest to ours, with a regret of $O(T^{2/3})$. Hazan et al~\cite{hazan2011newtron} proposed an algorithm with $O(\sqrt{T})$ regret but designed for the $\log$ loss, with coefficient that may be very large, and another~\cite{DBLP:journals/ml/CrammerG13} algorithm has $O(\sqrt{T})$ regret with respect to prediction mistakes, yet they assumed stochastic labeling, rather than adversarial.


% \begin{itemize}
% \item ask $\kappa$ queries, by sampling with no replacements.
% \kc{compute the bound please}
% \item ECOC (cor below)
% \item 1-vs-rest = contextual bandits with decoupled exploration and
%   exploitation (add)
% \item 1-vs-1 = contextual dueling bandits, with a dont relevant input, with decoupled exploration and
%   exploitation (add)

%\end{itemize}
\subsection{One-vs-One}
\label{sec:variants}
In the second setting, termed by {\em one-vs-one}, the algorithm picks two labels $\bar{Y}^+_t,\bar{Y}^-_t \in\{1 \dots C\}$, possibly both not the predicted label. The feedback for the learner is three-fold, it is $\yi{J_t,t}=+1$ if the first alternative is the correct label, $\bar{Y}^+_t=Y_t$. The feedback is $\yi{J_t,t}=-1$ if the second alternative is the correct label, $\bar{Y}^-_t=Y_t$, and it is $\yi{J_t,t}=0$ otherwise (in this case there is no error and we set $M_{J_t,t}=0$). The reduction we perform is by introducing $K= {C \choose 2}$ problems, one per pair of classes.  The goal of the learning algorithm for a problem indexed with two labels $(y_1,y_2)$ is to decide which is the correct label, given it is one of the two. Given the output of all (binary) classifiers the algorithm generates a single multi-class prediction using a tournament in a round-robin approach~\cite{DBLP:journals/jmlr/Furnkranz02}. If there is no clear winner, a random prediction is used. We now analyze the performance of this reduction as a multiclass prediction algorithm,
\begin{corollary} 
Assume the SHAMPO algorithm is executed as above, with $K={C \choose 2}$ one-vs-one problems, on a sequence $(\vx_1,Y_1),...(\vx_n,Y_n)\in\mathbb{R}^d\times\{1,...,C\}$, and input parameter $b>0$. Then for all $\gamma>0$ and all $\vui{i}\in\mathbb{R}^d$, the expected number of multi-class errors can be bounded as follows
\[
\begin{split}
&\mathbb{E}\brackets{\sum_t \1{Y_t \neq \hat{Y}_t}}\le \\
&\frac{2{C \choose 2}}{({C \choose 2}-1)/2+1} \frac{1}{\gamma}\brackets{\paren{1+\frac{X^2}{2b} }{\bar L}_{\gamma,n}+\frac{\paren{{2b+X^2}}^2U^{2}}{8{\gamma}b}}
\end{split}
\]
where $\1{A}=1$ if the predicate $A$ is true, and zero otherwise.
\end{corollary}
The corollary follows directly from \thmref{thm:bound} by noting that, $\1{Y_t \neq \hat{Y}_t} \leq \frac{2}{({C \choose 2}-1)/2+1}\sum_{i=1}^{ {C \choose 2}} M_{i,t}$. Note, that the bound is essentially  independent of $C$ as the coefficient in the bound is upper bounded by $6$ for $C \geq 3$.

We conclude this section with two algorithmic modifications, which we employ in this setting. Currently, when the feedback is zero, there is no update of the weights  for those problems, because there is no error. This causes the algorithm to effectively ignore such (many) examples, as in these cases the algorithm is not modifying any model, and furthermore, if such example is repeated, a problem with possibly ``0'' feedback may be queried again. 
%
We fix this issue with one of the two modifications. In the first alternative, if the feedback is zero, we modify the model to reduce the chance that the chosen problem, $J_t$, would be chosen again for the same input (i.e. not to make the same wrong-choice of choosing irrelevant problem again). To this end, we modify the weights a bit, to increase the confidence (absolute margin) of the model for the same input, and replace \eqref{perc_update} with,
\(
\vwi{J_t,t} = \vwi{J_t,t-1}+ \1{\yi{J_t,t}\ne0} \, \yi{J_t,t}\, \vxi{J_t,t} +
 \1{\yi{J_t,t}=0} \eta \hyi{J_t,t}\vxi{J_t,t}~,
\)
for some $\eta>0$. In other words, if there is a possible error (i.e. $\yi{J_t,t}\ne0$) the update follows the Perceptron's rule. Otherwise, the weights are updated such that the absolute margin will increase, as $\vert \vwti{J_t,t} \vxi{J_t,t} \vert = \vert 
(\vwi{J_t,t-1}+ \eta \hyi{J_t,t}\vxi{J_t,t})^\top\vxi{J_t,t}\vert = \vert \vwti{J_t,t-1}\vxi{J_t,t}+ \eta \sign(\vwti{J_t,t-1}\vxi{J_t,t}) \Vert\vxi{J_t,t}\Vert^2 \vert = 
\vert \vwti{J_t,t-1}\vxi{J_t,t}\vert + \eta \Vert\vxi{J_t,t}\Vert^2 > \vert \vwti{J_t,t-1}\vxi{J_t,t}\vert$. We call this method {\em one-vs-one-weak}, as it performs weak updates when there is zero feedback. The second alternative is not to allow a zeroed value feedback, and if this is the case, to set the label to be either $+1$ or $-1$, randomly. Both alternates are evaluated below. We call this method {\em one-vs-one-random}.



